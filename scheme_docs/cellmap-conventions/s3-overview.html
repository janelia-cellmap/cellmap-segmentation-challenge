
<!DOCTYPE html>


<html lang="en" data-content_root="../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Outline &#8212; CellMap Segmentation Challenge</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!-- 
    this give us a css class that will be invisible only if js is disabled 
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=26a4bc78f4c0ddb94549" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../_static/styles/sphinx-book-theme.css?v=a3416100" />
  
  <!-- So that users can add custom icons -->
  <script src="../../_static/scripts/fontawesome.js?digest=26a4bc78f4c0ddb94549"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549" />

    <script src="../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'scheme_docs/cellmap-conventions/s3-overview';</script>
    <link rel="icon" href="https://raw.githubusercontent.com/janelia-cellmap/cellmap-data/main/docs/source/_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  <meta name="docsearch:version" content="" />
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="https://raw.githubusercontent.com/janelia-cellmap/cellmap-data/main/docs/source/_static/CellMapLogo.png" class="logo__image only-light" alt="CellMap Segmentation Challenge - Home"/>
    <img src="https://raw.githubusercontent.com/janelia-cellmap/cellmap-data/main/docs/source/_static/CellMapLogo.png" class="logo__image only-dark pst-js-only" alt="CellMap Segmentation Challenge - Home"/>
  
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../cellmap-schemas.html">CellMap Schemas</a></li>


</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../cellmap_segmentation_challenge.train.html">cellmap_segmentation_challenge.train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../cellmap_segmentation_challenge.predict.html">cellmap_segmentation_challenge.predict</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/scheme_docs/cellmap-conventions/s3-overview.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Outline</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Outline</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cosem">COSEM</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#s3-layout">S3 layout</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-dataset">What is a dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-names">Dataset names</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datasets-on-s3">Datasets on S3</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-layout">Image layout</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chunked-array-format">Chunked array format</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-image-alignments">Multiple image alignments</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiresolution-image-layout">Multiresolution image layout</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#multiscale-image-metadata">Multiscale image metadata</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#downsampling-and-coordinates">Downsampling and coordinates</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="outline">
<h1>Outline<a class="headerlink" href="#outline" title="Link to this heading">#</a></h1>
<p>This document will explain the conventions for file layouts and metadata used for imaging data produced by the COSEM / Cellmap project team. Some historical background will be provided as needed to explain certain design decisions.</p>
<section id="cosem">
<h2>COSEM<a class="headerlink" href="#cosem" title="Link to this heading">#</a></h2>
<p><a class="reference external" href="https://www.janelia.org/project-team/cosem">COSEM</a> (<a href="#id2"><span class="problematic" id="id3">*</span></a>C*ellular <a href="#id4"><span class="problematic" id="id5">*</span></a>O*rganelle <a href="#id6"><span class="problematic" id="id7">*</span></a>S*egmentation in <a href="#id8"><span class="problematic" id="id9">*</span></a>E*lection <a href="#id10"><span class="problematic" id="id11">*</span></a>M*icroscopy) is the name of a project team that ran at <a class="reference external" href="https://www.janelia.org/">Janelia Research Campus</a> for several years starting in 2019. The goal of this project team was use machine learning to generate complete segmentations of cellular organelles in electron microscopy images, and to distribute the resulting raw data, methods, and results widely.</p>
<p>This effort was successful, resulting in <a class="reference external" href="https://scholar.google.com/scholar?&amp;amp;as_sdt=0%2C5&amp;amp;q=janelia+COSEM&amp;amp;btnG=">several papers</a> and <a class="reference external" href="https://www.openorganelle.org/">OpenOrganelle</a>, a web-based data portal for browsing our imaging datasets. OpenOrganelle functions as a front-end for large imaging datasets that are (as of this writing) stored on <a class="reference external" href="https://aws.amazon.com/">Amazon Web Services</a> <a class="reference external" href="https://aws.amazon.com/s3/">S3</a> cloud storage platform with costs covered by the generosity of Amazon’s <a class="reference external" href="https://aws.amazon.com/opendata/">Open Data program</a>. The primary S3 bucket we use for hosting datasets is <code class="docutils literal notranslate"><span class="pre">s3://janelia-cosem-datasets</span></code>, which you can browse <a class="reference external" href="https://open.quiltdata.com/b/janelia-cosem-datasets/">here</a> via a third-party bucket browsing tool.</p>
<p>Because the strategy and technology developed by COSEM worked well, COSEM metamorphosed into a larger project team named <a class="reference external" href="https://www.janelia.org/project-team/cellmap">Cellmap</a>.  COSEM no longer exists as a projct team, but the COSEM name is still in use for projects that were started during the COSEM era (e.g., our s3 bucket). While we could in principle rename all of these resources from COSEM to Cellmap, we deemed that this would be needlessly disruptive to anyone currently linking to our data. We did however migrate our main Github organization from <span class="raw-html-md"><a href="https://github.com/janelia-cosem/"><code class="docutils literal"><span class="pre">janelia-cosem</span></code></a></span> to <span class="raw-html-md"><a href="https://github.com/janelia-cellmap/"><code class="docutils literal"><span class="pre">janelia-cellmap</span></code></a></span>, because Github provides a redirect link for every migrated repository, which makes the transition smooth.</p>
<p>So, in short, COSEM became Cellmap, but the COSEM name is still around, e.g. for old tools and resources. New tools and resources will generally use the name Cellmap.</p>
</section>
</section>
<section id="s3-layout">
<h1>S3 layout<a class="headerlink" href="#s3-layout" title="Link to this heading">#</a></h1>
<p>As noted in the previous section, Cellmap stores public datasets in a single S3 bucket named <code class="docutils literal notranslate"><span class="pre">janelia-cosem-datasets</span></code>. The following sections will explain the general structure of that S3 bucket, and the motivation for the decisions that led us to adopt this design.</p>
<section id="what-is-a-dataset">
<h2>What is a dataset<a class="headerlink" href="#what-is-a-dataset" title="Link to this heading">#</a></h2>
<p>For the purposes of the S3 storage backend, a “dataset” is
a collection of images, potentially from multiple modalities or analysis methods, that
all depict the same physical specimen. For example, if a tissue sample was imaged with fluorescence microscopy, followed by FIB-SEM imaging, and the resulting FIB-SEM data was used for generating segmentations, then the set <code class="docutils literal notranslate"><span class="pre">{fluorescence</span> <span class="pre">microscopy</span> <span class="pre">images,</span> <span class="pre">FIB-SEM</span> <span class="pre">images,</span> <span class="pre">segmentation</span> <span class="pre">images}</span></code> would comprise a “dataset”.</p>
<section id="dataset-names">
<h3>Dataset names<a class="headerlink" href="#dataset-names" title="Link to this heading">#</a></h3>
<p>By convention, datasets have structured names that start with an acronym or abbreviated form of the name of the institute that collected the data, followed by an underscore, followed by a human-readable, immutable, unique identifier for the dataset that may include some information about the sample or tissue that was imaged. We adopted this convention for a simple reason: we needed a standard name for public-facing datasets, and there wasn’t a better alternative available at the time.</p>
<p>Note that Cellmap often publishes datasets from collaborators, and these datasets may already have names that were used internally, but if an original name does not comply with this structure, then we coin a new name that does, and we try to keep track of the old name. The same is true for the individual images within the dataset.</p>
<p>Some explained examples:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">jrc_hela-2</span></code> is the name of a dataset that contains images of <a class="reference external" href="https://en.wikipedia.org/wiki/HeLa">HeLa cells</a> imaged at Janelia Research Campus (jrc). The “2” at the end of the name denotes that this dataset is the second <code class="docutils literal notranslate"><span class="pre">jrc_hela</span></code> dataset in a sequence.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">jrc_mus-pacinian-corpuscle</span></code> is the name of a dataset that contains images of mouse <a class="reference external" href="https://en.wikipedia.org/wiki/Pacinian_corpuscle">Pacinian corpuscle</a> acquired at Janelia Research Campus (jrc). This dataset has no number suffix because it is not part of a sequence. If that were to change, i.e. if another mouse Pacinian corpuscle was imaged, then the name of this dataset would stay unchanged, and the subsequent dataset would be called <code class="docutils literal notranslate"><span class="pre">jrc_mus-pacininan-corpuscle-2</span></code>.</p></li>
</ul>
</section>
</section>
<section id="datasets-on-s3">
<h2>Datasets on S3<a class="headerlink" href="#datasets-on-s3" title="Link to this heading">#</a></h2>
<p>The top level of the <code class="docutils literal notranslate"><span class="pre">s3://janelia-cosem-datasets</span></code> bucket contains a list of prefixes (directories, in the parlance of local file systems), where each prefix is the name of a dataset. <code class="docutils literal notranslate"><span class="pre">s3://janelia-cosem-datasets/jrc_hela-2</span></code> is a URL to such a prefix. All of the images in the <code class="docutils literal notranslate"><span class="pre">jrc_hela-2</span></code> dataset are located under this prefix.</p>
<p>The following objects / prefixes can be found under <code class="docutils literal notranslate"><span class="pre">s3://janelia-cosem-datasets/&amp;lt;dataset&amp;gt;/</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">thumbnail.jpg</span></code>: A thumbnail image for the dataset, often a screenshot taken of Neuroglancer or some other visulization tool displaying a selection of images from the dataset. This file is used by OpenOrganelle. Every dataset should have a <code class="docutils literal notranslate"><span class="pre">thumbnail.jpg</span></code> file.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">&amp;lt;dataset&amp;gt;.n5/</span></code>: This prefix is the root of the N5 hierarchy for images that comprise the dataset which are stored in the N5 format. As of this writing, every dataset should have an N5 hierarchy root. However, we intend to migrate from N5 to Zarr, and thus newer datasets may not have an N5 hierachy. Instead, these datasets would have a prefix called <code class="docutils literal notranslate"><span class="pre">&amp;lt;dataset&amp;gt;.zarr</span></code>. For continuity, datasets that have been migrated from N5-based storage to Zarr-based storage will keep the original <code class="docutils literal notranslate"><span class="pre">&amp;lt;dataset&amp;gt;.n5</span></code> hierarchy until we feel it is safe to remove it.</p></li>
<li><p><cite>neuroglancer/em/</cite>: This prefix contains FIB-SEM images stored in the [Neuroglancer “precomputed” volume format](<a class="github reference external" href="https://github.com/google/neuroglancer/blob/master/src/neuroglancer/datasource/precomputed/volume.md">google/neuroglancer</a>). We used this format for a handful of datasets that were created early in the history of COSEM. At the time, the Neuroglancer “precomputed” format was chosen because it supports lossy JPEG compression, resulting in a smaller storage footprint. But use of the format never extended beyond a few older datasets, e.g., <span class="raw-html-md"><a href="https://open.quiltdata.com/b/janelia-cosem-datasets/tree/jrc_hela-2/neuroglancer/em/"><code class="docutils literal"><span class="pre">jrc_hela-2</span></code></a></span>. To be consistent with the <code class="docutils literal notranslate"><span class="pre">.n5</span></code> and <code class="docutils literal notranslate"><span class="pre">.zarr</span></code> suffix used by the N5 and Zarr formats respectively, images stored in the Neuroglancer precomputed format are stored under a prefix using the <code class="docutils literal notranslate"><span class="pre">.precomputed</span></code> suffix (e.g., <a class="reference external" href="https://open.quiltdata.com/b/janelia-cosem-datasets/tree/jrc_hela-2/neuroglancer/em/fibsem-uint8.precomputed/">this example</a>)</p></li>
<li><p><cite>neuroglancer/mesh/</cite>: This prefix contains meshes stored in the [Neuroglancer “precomputed” mesh format](<a class="github reference external" href="https://github.com/google/neuroglancer/blob/master/src/neuroglancer/datasource/precomputed/meshes.md">google/neuroglancer</a>) (e.g., <a class="reference external" href="https://open.quiltdata.com/b/janelia-cosem-datasets/tree/jrc_mus-liver/neuroglancer/mesh/mito_seg/">this example</a>). Meshes are generated from segmentation images, and by convention we give the mesh the same name as the image it came from. So in the above example, the mesh data is stored under the prefix <code class="docutils literal notranslate"><span class="pre">&amp;lt;dataset&amp;gt;/neuroglancer/mesh/mito_seg/</span></code>, because it came from an <a class="reference external" href="https://open.quiltdata.com/b/janelia-cosem-datasets/tree/jrc_mus-liver/jrc_mus-liver.n5/labels/mito_seg/">image</a> stored under the prefix <code class="docutils literal notranslate"><span class="pre">&amp;lt;dataset&amp;gt;/&amp;lt;dataset&amp;gt;.n5/labels/mito_seg/</span></code>. The coicindent naming is merely a convention, and could change at any time.</p></li>
</ul>
<p>The force shaping this layout is the need to partition resources according to the tool that will create or consume them. All of the resources stored under the <code class="docutils literal notranslate"><span class="pre">neuroglancer/</span></code> prefix are specific to Neuroglancer; the data stored in the <code class="docutils literal notranslate"><span class="pre">&amp;lt;dataset&amp;gt;.n5/</span></code> prefix is specific to tools that understand the N5 format, etc. If a new tool comes along, we would likely introduce a new prefix with that tool’s name, and store resources specific to that tool under that prefix.</p>
</section>
<section id="image-layout">
<h2>Image layout<a class="headerlink" href="#image-layout" title="Link to this heading">#</a></h2>
<section id="chunked-array-format">
<h3>Chunked array format<a class="headerlink" href="#chunked-array-format" title="Link to this heading">#</a></h3>
<p>We currently use the <code class="docutils literal notranslate"><span class="pre">`N5</span></code> format &lt;<a class="github reference external" href="https://github.com/saalfeldlab/n5">saalfeldlab/n5</a>&gt;`_ to store the bulk of the imaging data on S3. This format was convenient for a variety of reasons:</p>
<ul class="simple">
<li><p>We were already using N5 internally before we decided to publish data to S3.</p></li>
<li><p>N5 divides arrays into chunks, where each chunk is a separate object in storage. Thus it supports massively parallel reading and writing of arrays. This is essential for reading and writing multi-TB imaging datasets.</p></li>
<li><p>Neuroglancer can display images stored in N5.</p></li>
</ul>
<p>Within an N5 hierarchy (i.e., under the prefix <code class="docutils literal notranslate"><span class="pre">&amp;lt;dataset&amp;gt;.n5/</span></code>), we aim to partition different images according to the method of their production.</p>
<ul class="simple">
<li><p>Electron microscopy images are stored under a prefix with the scheme: <code class="docutils literal notranslate"><span class="pre">&amp;lt;dataset&amp;gt;.n5/em/&amp;lt;em</span> <span class="pre">modality&amp;gt;-&amp;lt;numpy-style</span> <span class="pre">data</span> <span class="pre">type</span> <span class="pre">specifier&amp;gt;/</span></code>, e.g. <span class="raw-html-md"><a href="https://open.quiltdata.com/b/janelia-cosem-datasets/tree/jrc_hela-2/jrc_hela-2.n5/em/fibsem-uint16/"><code class="docutils literal"><span class="pre">jrc_hela-2.n5/em/fibsem-uint16/</span></code></a></span>, which is 16 bit FIB-SEM data. We include the data type in the name of these datasets to ensure that 8 bit and 16 bit versions of the same image can share the same prefix. We have at least one <a class="reference external" href="https://en.wikipedia.org/wiki/Transmission_electron_microscopy">TEM</a> dataset, which is stored at <span class="raw-html-md"><a href="https://open.quiltdata.com/b/janelia-cosem-datasets/tree/jrc_dauer-larva/jrc_dauer-larva.n5/em/tem-uint8/"><code class="docutils literal"><span class="pre">jrc_dauer-larva.n5/em/tem-uint8</span></code></a></span>.</p></li>
<li><p>Light microscopy images are stored under a prefix with the scheme <code class="docutils literal notranslate"><span class="pre">&amp;lt;dataset&amp;gt;.n5/lm/&amp;lt;identifier&amp;gt;/</span></code>, e.g. <span class="raw-html-md"><a href="https://open.quiltdata.com/b/janelia-cosem-datasets/tree/aic_desmosome-2/aic_desmosome-2.n5/lm/lm_488/"><code class="docutils literal"><span class="pre">aic_desmosome-2.n5/lm/lm_488</span></code></a></span>, <span class="raw-html-md"><a href="https://open.quiltdata.com/b/janelia-cosem-datasets/tree/jrc_cos7-11/jrc_cos7-11.n5/lm/er_palm/"><code class="docutils literal"><span class="pre">jrc_cos7-11.n5/lm/er_palm</span></code></a></span>. Note that the image identifiers are not consistently structured. Historically, light microscopy images have been rarer than electron microscopy images, and so we have been under less pressure to be consistent / strict about the naming of these images. This may change in the future, especially if we do an overhaul of our storage strategy.</p></li>
<li><p>Segmentation, prediction, and other derived images are stored under a prefix with the scheme <code class="docutils literal notranslate"><span class="pre">&amp;lt;dataset&amp;gt;.n5/labels/&amp;lt;image-name&amp;gt;</span></code>, e.g. <span class="raw-html-md"><a href="https://open.quiltdata.com/b/janelia-cosem-datasets/tree/jrc_macrophage-2/jrc_macrophage-2.n5/labels/mito_seg/"><code class="docutils literal"><span class="pre">jrc_macrophage-2.n5/labels/mito_seg</span></code></a></span>, which is segmentation of mitochondria. Many of our machine learning models do not directly produce segmentations (i.e., images where sample values map to distinct semantic classes) – instead, they emit a <em>prediction</em>, which is a scalar value indicating the model’s estimate of the distance to the nearest instance of a target semantic class. Segmentation images are generated by thresholding these prediction images, and we currently store the predictions and segmentations together. So <span class="raw-html-md"><a href="https://open.quiltdata.com/b/janelia-cosem-datasets/tree/jrc_macrophage-2/jrc_macrophage-2.n5/labels/mito_pred/"><code class="docutils literal"><span class="pre">jrc_macrophage-2.n5/labels/mito_pred</span></code></a></span> is the location of the prediction image that was used to generate <span class="raw-html-md"><a href="https://open.quiltdata.com/b/janelia-cosem-datasets/tree/jrc_macrophage-2/jrc_macrophage-2.n5/labels/mito_seg/"><code class="docutils literal"><span class="pre">jrc_macrophage-2.n5/labels/mito_seg</span></code></a></span>.</p></li>
</ul>
<section id="multiple-image-alignments">
<h4>Multiple image alignments<a class="headerlink" href="#multiple-image-alignments" title="Link to this heading">#</a></h4>
<p>So far we have assumed (and ensured) that all the images in a dataset are aligned to the same coordinate space. This means that these images can all be viewed together in a single visualization tool. But image alignment is an art, and there may be multiple different, yet equally valid, alignments generated from the same raw images. With the layout described above, we cannot store different alignments of the same data under the constraint that all images in a dataset share the same coordinate space. This is a limitation that we plan to address when we overhaul the layout at some future date.</p>
</section>
</section>
<section id="multiresolution-image-layout">
<h3>Multiresolution image layout<a class="headerlink" href="#multiresolution-image-layout" title="Link to this heading">#</a></h3>
<p>Cellmap’s imagery has features at many spatial scales, and we want users to be able to visualize these features interactively. A typical interactive visualization workflow might involve zooming out of an image to look for some large feature or region of interest, then zooming in to see fine-scale details. If we only published images at the highest level of detail, then the “zooming out” operation would force visualization programs to load an enormous amount of data, which would impair interactive visualization.</p>
<p>We solve this problem in a very common way – by generating an <a class="reference external" href="https://en.wikipedia.org/wiki/Pyramid_%28image_processing%29">image pyramid</a>, also known as a multiscale respresentation, from our images. This storage technique gives visualization clients access to smaller, coarser copies of the data, which they can load when a user is viewing a zoomed-out scene. We store the images as N5 datasets (arrays) inside an N5 group. You can see an example <a class="reference external" href="https://open.quiltdata.com/b/janelia-cosem-datasets/tree/jrc_mus-liver/jrc_mus-liver.n5/labels/mito_seg/">here</a>. Conventionally, the different scale level arrays are named <code class="docutils literal notranslate"><span class="pre">s0</span></code>, <code class="docutils literal notranslate"><span class="pre">s1</span></code>, <code class="docutils literal notranslate"><span class="pre">s2</span></code>…, where <code class="docutils literal notranslate"><span class="pre">s0</span></code> is the largest image (i.e., the original), <code class="docutils literal notranslate"><span class="pre">s1</span></code> was downscaled once, <code class="docutils literal notranslate"><span class="pre">s2</span></code> was downscaled twice, etc.</p>
<p>Saving multiple arrays at different levels of detail addresses the interactive visualization problem, but it introduces some additional complications.</p>
<section id="multiscale-image-metadata">
<h4>Multiscale image metadata<a class="headerlink" href="#multiscale-image-metadata" title="Link to this heading">#</a></h4>
<p>Instead of representing a single image as a single array in storage, we represent an image as a <em>collection</em> of arrays, that are similar in some ways (they have the same number of dimensions, and the same axis names) but different in others (they are different sizes, and their coordinates are different). To build software that works with multscale images, one must distinguish a multiscale image collection from a collection of random images that happen to be stored together, which typically entails declaring some special multiscale-specific metadata that consuming applications can correctly parse.</p>
<p>Because Cellmap was using N5 for storing our published images and Neuroglancer for viewing them, we solved the “multiscale image metadata problem” by complying with the Neuroglancer N5 multiscale metadata convention, which you can find documented <a class="reference external" href="https://github.com/google/neuroglancer/tree/master/src/neuroglancer/datasource/n5">here</a>. This repository contains Python code for creating / validating this metadata, which you can find documented <a class="reference external" href="../api/multiscale/neuroglancer_n5.md">here</a>.</p>
<p>Additionally, to ensure that Neuroglancer and other N5-fluent tools can open individual arrays with the correct coordinate scaling, each scale level array has a <span class="raw-html-md"><a href="../api/multiscale/neuroglancer_n5.md#cellmap_schemas.multiscale.neuroglancer_n5.PixelResolution"><code class="docutils literal"><span class="pre">PixelResolution</span></code></a></span> defined in its attributes.</p>
</section>
<section id="downsampling-and-coordinates">
<h4>Downsampling and coordinates<a class="headerlink" href="#downsampling-and-coordinates" title="Link to this heading">#</a></h4>
<p>The different scale levels of a multiscale image have different coordinates (locations in space), and the change in coordinates induced by downscaling depends on the method used to downscale. If we coarsen a 2D image by a factor of 2 along each axis by averaging contiguous, non-overlapping blocks of 2x2 samples, then it’s obvious that adjacent samples of the resulting image are twice as far apart from each other than adjacent samples in the source image. But it’s less obvious that the <em>origin</em> of the coarsened image has also moved relative to the origin of the source image, specifically, by 0.5 * the the inter-sample distance of the source image. In other words, this form of coarsening applies a <em>scaling</em>, and a <em>translation</em> to the coordinate grid of the coarsened image, relative to the coordinate grid of the source image. To further complicate matters, different downscaling techniques may apply different amounts of translation – if, instead of taking a windowed average, we simply subsample the source image, then the translation applied by this operation depends on which samples we kept – if we keep the “corner samples”, including the origin, then there is no translation at all.</p>
<p>the Neuroglancer N5 multiscale conventions cannot express this information, because they do not support declaring translation transformations for each scale level. So we invented two pieces of metadata: The first, stored under the <code class="docutils literal notranslate"><span class="pre">transform</span></code> key in array attributes, specifies, for each axis, a name, unit, scaling, translation parameter. The purpose of this metadata is to compactly express a downscaled coordinate grid. This metadata is implemented in Python in this project; see the documentation <a class="reference external" href="../api/multiscale/cosem.md#cellmap_schemas.multiscale.cosem.STTransform">here</a>. The second piece of metadata is stored under the <code class="docutils literal notranslate"><span class="pre">multiscales</span></code> key in the attributes of the group containing the scale level arrays. <code class="docutils literal notranslate"><span class="pre">multiscales</span></code> is a list of JSON objects that provide, for each scale level array, a relative path and a transform object as described in the previous section. This metadata also has a Python implementation in this project; see its documentation <a class="reference external" href="../api/multiscale/cosem.md#cellmap_schemas.cosem.multiscale.GroupMetadata">here</a></p>
<p>When Cellmap started publishing our data there was no community standard for storing multiresolution images in a chunked format that satisfied our needs, so we pieced together our own conventions. With the advent of <a class="reference external" href="https://ngff.openmicroscopy.org/">OME-NGFF</a>, it’s less and less attractive for us to maintain a home-grown convention when a community-maintained one exists. We intend to ultimately use OME-NGFF whereever we can, but this will require converting a <em>lot</em> of data, so it will take time.</p>
</section>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Outline</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cosem">COSEM</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#s3-layout">S3 layout</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-is-a-dataset">What is a dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-names">Dataset names</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#datasets-on-s3">Datasets on S3</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-layout">Image layout</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#chunked-array-format">Chunked array format</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#multiple-image-alignments">Multiple image alignments</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multiresolution-image-layout">Multiresolution image layout</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#multiscale-image-metadata">Multiscale image metadata</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#downsampling-and-coordinates">Downsampling and coordinates</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Jeff Rhoades, Emma Avetissian, Davis Vann Bennett, Marwan Zouinkhi
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024, Jeff Rhoades, Emma Avetissian, Davis Vann Bennett, Marwan Zouinkhi.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../_static/scripts/bootstrap.js?digest=26a4bc78f4c0ddb94549"></script>
<script defer src="../../_static/scripts/pydata-sphinx-theme.js?digest=26a4bc78f4c0ddb94549"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>